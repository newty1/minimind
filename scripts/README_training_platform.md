# MiniMind训练云平台使用说明

## 简介

MiniMind训练云平台是一个基于Streamlit开发的Web界面，用于简化MiniMind大语言模型的训练流程。通过可视化界面，用户可以轻松创建、管理和监控训练任务，无需深入了解命令行操作。

## 功能特性

### 1. 创建训练任务
- **训练类型选择**：支持多种训练模式
  - 预训练 (Pretrain)
  - 监督微调 (SFT)
  - LoRA微调
  - DPO/PPO/GRPO/SPO强化学习
  - 推理模型蒸馏
  
- **可视化配置**：
  - 模型配置（隐藏层维度、层数、序列长度、MoE等）
  - 训练配置（轮数、批次大小、学习率等）
  - 数据集选择
  - 设备选择（GPU/CPU）

### 2. 任务监控
- **实时指标监控**：
  - Loss曲线
  - 学习率变化曲线
  - 训练步数
  - 训练轮数
  
- **实时日志查看**：显示训练过程的实时日志输出

### 3. 任务管理
- **任务列表**：查看所有训练任务（运行中/已完成/失败）
- **任务操作**：
  - 停止运行中的任务
  - 查看任务日志
  - 删除已完成的任务
- **任务筛选**：按状态和关键词筛选任务

### 4. 模型管理
- **模型文件列表**：显示所有训练完成的模型权重文件
- **模型信息**：文件大小、修改时间等
- **模型下载**：下载训练完成的模型文件

## 安装依赖

确保已安装所有依赖：

```bash
pip install -r requirements.txt
```

新增依赖包括：
- `plotly==5.18.0`：用于绘制训练指标图表

## 启动平台

### 基本启动

```bash
cd scripts
streamlit run training_platform.py
```

启动后，浏览器会自动打开Web界面（默认地址：http://localhost:8501）

### 自定义端口和地址

Streamlit启动时会显示三个URL：
- **Local URL**: `http://localhost:8501` - 本机访问地址
- **Network URL**: `http://10.129.227.177:8501` - 局域网访问地址（自动检测）
- **External URL**: `http://115.27.212.110:8501` - 外部访问地址（如果有公网IP）

#### 方法1：命令行参数

```bash
# 指定端口
streamlit run training_platform.py --server.port 8503

# 指定端口和地址
streamlit run training_platform.py --server.port 8503 --server.address 0.0.0.0

# 指定端口、地址和启用CORS
streamlit run training_platform.py --server.port 8503 --server.address 0.0.0.0 --server.enableCORS false
```

#### 方法2：配置文件

创建配置文件 `.streamlit/config.toml`（在项目根目录下）：

```toml
[server]
port = 8503
address = "0.0.0.0"  # 0.0.0.0 允许所有IP访问，127.0.0.1 只允许本机访问
enableCORS = false
enableXsrfProtection = true

[browser]
gatherUsageStats = false
serverAddress = "localhost"
```

#### 方法3：环境变量

```bash
# 设置端口
export STREAMLIT_SERVER_PORT=8503

# 设置地址
export STREAMLIT_SERVER_ADDRESS=0.0.0.0

# 然后启动
streamlit run training_platform.py
```

#### 常用配置选项

| 参数 | 说明 | 默认值 |
|------|------|--------|
| `--server.port` | 端口号 | 8501 |
| `--server.address` | 监听地址（0.0.0.0=所有接口，127.0.0.1=仅本机） | 0.0.0.0 |
| `--server.enableCORS` | 启用CORS | true |
| `--server.enableXsrfProtection` | 启用XSRF保护 | true |
| `--browser.gatherUsageStats` | 收集使用统计 | true |

## 使用流程

### 1. 创建训练任务

1. 在侧边栏选择"创建训练任务"
2. 选择训练类型（如：监督微调）
3. 选择数据集（或手动输入数据集路径）
4. 配置模型参数：
   - 隐藏层维度（如：512）
   - 隐藏层数量（如：8）
   - 最大序列长度（如：340）
   - 是否使用MoE架构
5. 配置训练参数：
   - 训练轮数
   - 批次大小
   - 学习率
   - 梯度累积步数
   - 梯度裁剪阈值
6. 配置其他参数：
   - 训练设备（cuda:0/cuda:1/cpu）
   - 数据类型（bfloat16/float16/float32）
   - 基础权重（pretrain/full_sft/none）
   - 是否启用断点续训
7. 点击"提交训练任务"按钮

### 2. 监控训练任务

1. 在侧边栏选择"任务监控"
2. 从下拉列表中选择要监控的任务
3. 查看实时训练指标图表：
   - Loss曲线
   - 学习率变化
   - 训练进度（步数/轮数）
4. 查看实时训练日志

### 3. 管理任务

1. 在侧边栏选择"任务管理"
2. 使用筛选器查找任务：
   - 按状态筛选（全部/运行中/已完成/失败等）
   - 按关键词搜索（任务ID或训练类型）
3. 对任务进行操作：
   - 停止运行中的任务
   - 查看任务详细日志
   - 删除不需要的任务

### 4. 管理模型

1. 在侧边栏选择"模型管理"
2. 查看所有训练完成的模型文件
3. 下载模型文件
4. （开发中）转换模型格式

## 数据存储

- **任务数据**：保存在 `../tasks.json` 文件中
- **训练日志**：实时保存在内存中，任务完成后可查看历史记录
- **训练指标**：实时保存在内存中，用于绘制图表
- **模型文件**：保存在 `../out/` 目录下

## 注意事项

1. **资源限制**：
   - 确保有足够的GPU显存
   - 监控系统资源使用情况
   - 避免同时运行过多训练任务

2. **数据集路径**：
   - 数据集文件应放在 `../dataset/` 目录下
   - 或使用绝对路径指定数据集位置

3. **任务管理**：
   - 停止任务前请确保已保存必要的检查点
   - 任务删除后无法恢复，请谨慎操作

4. **性能考虑**：
   - 日志缓冲区限制为最近100行
   - 指标数据限制为最近500个数据点
   - 对于长时间训练任务，建议定期保存检查点

## 常见问题

### Q: 任务启动失败？
A: 检查以下几点：
- 数据集路径是否正确
- 训练脚本是否存在
- GPU是否可用（如果选择了cuda设备）
- 是否有足够的显存

### Q: 如何查看完整日志？
A: 在"任务管理"页面点击"查看日志"按钮，可以查看任务的完整日志历史。

### Q: 任务状态没有更新？
A: 点击页面刷新按钮或重新选择页面，可以刷新任务状态。

### Q: 如何恢复训练？
A: 在创建任务时勾选"启用断点续训"，系统会自动检测并加载检查点。

## 技术架构

- **前端框架**：Streamlit
- **图表库**：Plotly
- **进程管理**：subprocess + threading
- **数据存储**：JSON文件 + 内存缓存

## 后续开发计划

1. **模型转换功能**：支持PyTorch和Transformers格式互转
2. **分布式训练支持**：支持多GPU分布式训练
3. **资源监控**：GPU使用率、显存占用等实时监控
4. **任务队列**：支持任务排队和优先级管理
5. **用户认证**：多用户支持和权限管理
6. **模型评估**：集成模型评估功能
7. **自动超参数优化**：支持超参数自动搜索

## 反馈与支持

如有问题或建议，请提交Issue或联系开发团队。

